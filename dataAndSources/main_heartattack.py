# -*- coding: utf-8 -*-
"""Main_HeartAttack.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uQjgWAXuVrek4I3EeKkodPD_YpmuYczh
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
sns.set(color_codes=True)
# %matplotlib inline

"""## Loading and Reviewing the Data"""

data_frame = pd.read_csv("stroke_prediction_dataset.csv")

data_frame.shape

data_frame.head(8)

data_frame.tail(5)

"""## Check for null values"""

print (data_frame.isnull().values.any())

"""### Correlated Feature Check

Helper function that displays correlation by color.  Red is most correlated, Blue least.
"""

def plot_corr(data_frame, size=11):
    """
    Function plots a graphical correlation matrix for each pair of columns in the dataframe.

    Input:
        data_frame: pandas DataFrame
        size: vertical and horizontal size of the plot

    Displays:
        matrix of correlation between columns.  Blue-cyan-yellow-red-darkred => less to more correlated
                                                0 ------------------>  1
                                                Expect a darkred line running from top left to bottom right
    """

    corr = data_frame.corr()    # data frame correlation function
    fig, ax = plt.subplots(figsize=(size, size))
    ax.matshow(corr)   # color code the rectangles by correlation value
    plt.xticks(range(len(corr.columns)), corr.columns)  # draw x tick marks
    plt.yticks(range(len(corr.columns)), corr.columns)  # draw y tick marks

data_frame.corr()

data_frame.head(7)

"""The skin and thickness columns are correlated 1 to 1.  Dropping the skin column"""

data_frame.head(7)

"""Check for additional correlations"""

plot_corr(data_frame)

"""## Mold Data

### Data Types

Inspect data types to see if there are any issues.  Data should be numeric.
"""

data_frame.head(7)

"""Change diabetes from boolean to integer, True=1, False=0

Verify that the diabetes data type has been changed.
"""

data_frame.head(5)

"""### Check for null values"""

data_frame.isnull().values.any()

"""No obvious null values.

### Check class distribution

Rare events are hard to predict
"""

num_obs = len(data_frame)
num_true = len(data_frame.loc[data_frame['Diag0sis'] == 1])
num_false = len(data_frame.loc[data_frame['Diag0sis'] == 0])
print("Number of True cases:  {0} ({1:2.2f}%)".format(num_true, ((1.00 * num_true)/(1.0 * num_obs)) * 100))
print("Number of False cases: {0} ({1:2.2f}%)".format(num_false, (( 1.0 * num_false)/(1.0 * num_obs)) * 100))

"""Good distribution of true and false cases.  No special work needed.

### Spliting the data

70% for training, 30% for testing
"""

from sklearn.model_selection import train_test_split

feature_col_names = ['Age', 'Gender', 'Hypertension', 'Heart Disease',
                     'Body Mass Index (BMI)', 'Smoking Status', 'Alcohol Intake', 'Physical Activity', '1 History', 'Family History of 1',
                     'Dietary Habits', 'HDL Cholesterol Levels', 'LDL Cholesterol Levels', 'Stress Levels', 'Blood Pressure Thu', 'Blood Pressure Truong']
predicted_class_names = ['Diag0sis']

X = data_frame[feature_col_names].values     # predictor feature columns (8 X m)
y = data_frame[predicted_class_names].values # predicted class (1=true, 0=false) column (1 X m)
split_test_size = 0.3

#Splitting Data from 2 different Datasets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=split_test_size, random_state=42)
                            # test_size = 0.3 is 30%, 42 is the answer to everything

"""We check to ensure we have the the desired 70% train, 30% test split of the data"""

trainval = (1.0 * len(X_train)) / (1.0 * len(data_frame.index))
testval = (1.0 * len(X_test)) / (1.0 * len(data_frame.index))
print("{0:0.2f}% in training set".format(trainval * 100))
print("{0:0.2f}% in test set".format(testval * 100))

"""#### Verifying predicted value was split correctly"""

print("Original True  : {0} ({1:0.2f}%)".format(len(data_frame.loc[data_frame['Diag0sis'] == 1]), (len(data_frame.loc[data_frame['Diag0sis'] == 1])/len(data_frame.index)) * 100.0))
print("Original False : {0} ({1:0.2f}%)".format(len(data_frame.loc[data_frame['Diag0sis'] == 0]), (len(data_frame.loc[data_frame['Diag0sis'] == 0])/len(data_frame.index)) * 100.0))
print("")
print("Training True  : {0} ({1:0.2f}%)".format(len(y_train[y_train[:] == 1]), (len(y_train[y_train[:] == 1])/len(y_train) * 100.0)))
print("Training False : {0} ({1:0.2f}%)".format(len(y_train[y_train[:] == 0]), (len(y_train[y_train[:] == 0])/len(y_train) * 100.0)))
print("")
print("Test True      : {0} ({1:0.2f}%)".format(len(y_test[y_test[:] == 1]), (len(y_test[y_test[:] == 1])/len(y_test) * 100.0)))
print("Test False     : {0} ({1:0.2f}%)".format(len(y_test[y_test[:] == 0]), (len(y_test[y_test[:] == 0])/len(y_test) * 100.0)))

"""### Post-split Data Preparation

#### Hidden Missing Values

Are these 0 values possible?

How many rows have have unexpected 0 values?
"""

print("# rows in dataframe {0}".format(len(data_frame)))
print("# rows missing age: {0}".format(len(data_frame.loc[data_frame['age'] == 0])))
print("# rows missing hypertension: {0}".format(len(data_frame.loc[data_frame['hypertension'].isnull()])))
print("# rows missing heart_disease: {0}".format(len(data_frame.loc[data_frame['heart_disease'].isnull()])))
print("# rows missing bmi: {0}".format(len(data_frame.loc[data_frame['bmi'] == 0])))
print("# rows missing HbA1c_level: {0}".format(len(data_frame.loc[data_frame['HbA1c_level'] == 0])))
print("# rows missing blood_glucose_level: {0}".format(len(data_frame.loc[data_frame['blood_glucose_level'] == 0])))

"""## Training Initial Algorithm - Naive Bayes"""

from sklearn.naive_bayes import GaussianNB, MultinomialNB, CategoricalNB, BernoulliNB

# create Multinomial Naive Bayes model object and train it with the data
nb_model = MultinomialNB()

nb_model.fit(X_train, y_train.ravel())

"""## Performance on Training Data

"""

# this returns array of predicted results
prediction_from_trained_data = nb_model.predict(X_train)

from sklearn import metrics

accuracy = metrics.accuracy_score(y_train, prediction_from_trained_data)

print ("Accuracy of our naive bayes model is : {0:.4f}".format(accuracy))

"""## Performance on Testing Data"""

# this returns array of predicted results from test_data
from sklearn.metrics import confusion_matrix
prediction_from_test_data = nb_model.predict(X_test)

NB_accuracy = metrics.accuracy_score(y_test, prediction_from_test_data)

print ("Accuracy of our naive bayes model is: {0:0.4f}".format(NB_accuracy))

from sklearn import metrics
import matplotlib.pyplot as plt
confusion_matrix = metrics.confusion_matrix(y_test, prediction_from_test_data)
cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [False, True])
cm_display.plot()
plt.show()

print ("Classification Report")

# labels for set 1=True to upper left and 0 = False to lower right
print ("{0}".format(metrics.classification_report(y_test, prediction_from_test_data, labels=[1, 0])))

"""# Random Forest Classifier"""

from sklearn.ensemble import RandomForestClassifier

# Create a RandomForestClassifier object
rf_model = RandomForestClassifier(random_state=42)

rf_model.fit(X_train, y_train.ravel())

"""# Predict Training Data"""

rf_predict_train = rf_model.predict(X_train)

#get accuracy
rf_accuracy = metrics.accuracy_score(y_train, rf_predict_train)

#print accuracy
print ("Accuracy: {0:.4f}".format(rf_accuracy))

"""# Predict Testing Data"""

rf_predict_test = rf_model.predict(X_test)

#get accuracy
rf_accuracy_testdata = metrics.accuracy_score(y_test, rf_predict_test)

#print accuracy
print ("Accuracy: {0:.4f}".format(rf_accuracy_testdata))

print ("Confusion Matrix for Random Forest")

# labels for set 1=True to upper left and 0 = False to lower right
print ("{0}".format(metrics.confusion_matrix(y_test, rf_predict_test, labels=[1, 0])))

print ("")

print ("Classification Report\n")

# labels for set 1=True to upper left and 0 = False to lower right
print ("{0}".format(metrics.classification_report(y_test, rf_predict_test, labels=[1, 0])))

"""# Logistic Regression"""

from sklearn.linear_model import LogisticRegressionCV

lr_cv_model = LogisticRegressionCV(n_jobs=-1, random_state=42, Cs=3, cv=10, refit=False, class_weight="balanced")

# set number of jobs to -1 which uses all cores to parallelize
lr_cv_model.fit(X_train, y_train.ravel())

lr_cv_predict_test = lr_cv_model.predict(X_test)

lr_accuracy_test_data = metrics.accuracy_score(y_test, lr_cv_predict_test)

# training metrics
print( "Accuracy: {0:.4f}".format(lr_accuracy_test_data))
print (metrics.confusion_matrix(y_test, lr_cv_predict_test, labels=[1, 0]))
print ("")
print ("Classification Report")
print (metrics.classification_report(y_test, lr_cv_predict_test, labels=[1,0]))

"""# Support vector Machine"""

from sklearn.svm import SVC
# Create a RandomForestClassifier object
svm_model = SVC(kernel='linear', C=1, random_state=42)

svm_model.fit(X_train, y_train.ravel())

# this returns array of predicted results
prediction_from_trained_data = svm_model.predict(X_train)

from sklearn import metrics

accuracy = metrics.accuracy_score(y_train, prediction_from_trained_data)

print ("Accuracy of our SVM model is : {0:.4f}".format(accuracy))

svm_predict_test = svm_model.predict(X_test)

#get accuracy
svm_accuracy_testdata = metrics.accuracy_score(y_test, svm_predict_test)

#print accuracy
print ("Accuracy: {0:.4f}".format(svm_accuracy_testdata))

print ("Confusion Matrix for Support Vector Amchine")

# labels for set 1=True to upper left and 0 = False to lower right
print ("{0}".format(metrics.confusion_matrix(y_test, svm_predict_test, labels=[1, 0])))

print ("")

print ("Classification Report\n")

# labels for set 1=True to upper left and 0 = False to lower right
print ("{0}".format(metrics.classification_report(y_test, svm_predict_test, labels=[1, 0])))

def addlabels(x,y):
    for i in range(len(x)):
        plt.text(i,round(y[i], 3), round(y[i],3), ha = 'center')

import numpy as np
import matplotlib.pyplot as plt

Mean_accuracy = (NB_accuracy + rf_accuracy_testdata + svm_accuracy_testdata)/3

data = {'Naive Bayes': NB_accuracy, 'Random Forest':rf_accuracy_testdata, 'SVM':svm_accuracy_testdata, 'Mean': Mean_accuracy}
courses = list(data.keys())
values = list(data.values())

fig = plt.figure(figsize = (10, 5))

# creating the bar plot
plt.bar(courses, values, color ='maroon',
        width = 0.6)

addlabels(courses, values)

plt.xlabel("Model")
plt.ylabel("Accuracy")
plt.title("Cross-model verification")
plt.show()













